# 基础配置
yarn.standalone.appType=Spark
yarn.standalone.appName=SparkClusterOnYarn
yarn.standalone.queueName=default

yarn.standalone.am.mem=4
yarn.standalone.am.core=2
yarn.standalone.master.address=spark://172.16.170.130:7077

yarn.standalone.hdfs.extend.file=hdfs://ns1/tmp/yarnStandalone/registerdata.txt

# 设置环境变量
yarn.standalone.env.SPARK_WORKER_OPTS=""
yarn.standalone.env.SPARK_WORKER_DIR=""

# 指定Container的运行环境
#yarn.standalone.appMasterEnv.yarn.nodemanager.container-executor.class="DockerLinuxContainer"
#yarn.standalone.appMasterEnv.yarn.nodemanager.docker-container-executor.image-name="bdp-docker.jd.com:5000/tensorflow-image:beta3"
#yarn.standalone.env.yarn.nodemanager.container-executor.class="DockerLinuxContainer"
#yarn.standalone.env.yarn.nodemanager.docker-container-executor.image-name="bdp-docker.jd.com:5000/tensorflow-image:beta3"

yarn.standalone.hdfs.path=hdfs://ns1/tmp/yarnStandalone/
yarn.standalone.appmaster.tar=standalone-yarn.zip
yarn.standalone.tar=standalone.tar

# 设置worker相关
yarn.standalone.worker.core=8
yarn.standalone.worker.mem=16
yarn.standalone.worker.relax.locality=true
